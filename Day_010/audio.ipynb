{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b6dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 Microphone Array (Realtek(R) Au, MME (2 in, 0 out)\n",
      "   2 Headset (realme Buds T310), MME (1 in, 0 out)\n",
      "   3 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  4 Headphones (realme Buds T310), MME (0 in, 2 out)\n",
      "   5 Speaker (Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   6 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   7 Microphone Array (Realtek(R) Audio), Windows DirectSound (2 in, 0 out)\n",
      "   8 Headset (realme Buds T310), Windows DirectSound (1 in, 0 out)\n",
      "   9 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "  10 Headphones (realme Buds T310), Windows DirectSound (0 in, 2 out)\n",
      "  11 Speaker (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "  12 Headphones (realme Buds T310), Windows WASAPI (0 in, 2 out)\n",
      "  13 Speaker (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  14 Microphone Array (Realtek(R) Audio), Windows WASAPI (2 in, 0 out)\n",
      "  15 Headset (realme Buds T310), Windows WASAPI (1 in, 0 out)\n",
      "  16 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  17 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  18 Input (), Windows WDM-KS (2 in, 0 out)\n",
      "  19 Microphone Array (Realtek HD Audio Mic input), Windows WDM-KS (2 in, 0 out)\n",
      "  20 Stereo Mix (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  21 Speakers 1 (Realtek HD Audio output with HAP), Windows WDM-KS (0 in, 2 out)\n",
      "  22 Speakers 2 (Realtek HD Audio output with HAP), Windows WDM-KS (0 in, 2 out)\n",
      "  23 PC Speaker (Realtek HD Audio output with HAP), Windows WDM-KS (2 in, 0 out)\n",
      "  24 Mic in at front panel (black) (Mic in at front panel (black)), Windows WDM-KS (2 in, 0 out)\n",
      "  25 Headphones (Realtek HD Audio 2nd output), Windows WDM-KS (0 in, 2 out)\n",
      "  26 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Mivi DuoPods F70)), Windows WDM-KS (0 in, 1 out)\n",
      "  27 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Mivi DuoPods F70)), Windows WDM-KS (1 in, 0 out)\n",
      "  28 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(realme Buds T310)), Windows WDM-KS (0 in, 1 out)\n",
      "  29 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(realme Buds T310)), Windows WDM-KS (1 in, 0 out)\n",
      "  30 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  31 Output (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Adarsh's F41)), Windows WDM-KS (0 in, 1 out)\n",
      "  32 Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(Adarsh's F41)), Windows WDM-KS (1 in, 0 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2be15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7066992e",
   "metadata": {},
   "source": [
    "**using vosk converting live audio into text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening... speak now\n",
      "\n",
      "Final Output:\n",
      " mermaid the is turns out the real nice be will give him \n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import time\n",
    "import wave\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "model_path = 'D:/Infosys_Springboard/AI_Internship/vosk-model'\n",
    "vosk_model = Model(model_path)\n",
    "rec = KaldiRecognizer(vosk_model, 16000)\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "duration = 10  # seconds\n",
    "\n",
    "# File where audio will be saved\n",
    "output_file = \"recorded_audio.wav\"\n",
    "\n",
    "wf = wave.open(output_file,'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(2)\n",
    "wf.setframerate(16000)\n",
    "\n",
    "def callback(indata, frames, time_info, status):\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "with sd.RawInputStream(\n",
    "    samplerate=16000,\n",
    "    blocksize=4000,\n",
    "    dtype='int16',\n",
    "    channels=1,\n",
    "    callback=callback\n",
    "):\n",
    "    print(\"Listening... speak now\")\n",
    "\n",
    "    start = time.time()\n",
    "    result = \"\"\n",
    "\n",
    "    while time.time() - start < duration:\n",
    "        data = q.get()\n",
    "\n",
    "        wf.writeframes(data)\n",
    "\n",
    "        if rec.AcceptWaveform(data):\n",
    "            text = json.loads(rec.Result()).get(\"text\")\n",
    "            if text:\n",
    "                result += text + \" \"\n",
    "\n",
    "    # Final cleanup recognition\n",
    "    final_text = json.loads(rec.FinalResult()).get(\"text\")\n",
    "    if final_text:\n",
    "        result += final_text\n",
    "\n",
    "wf.close()\n",
    "\n",
    "print(\"\\nFinal Output:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bd4da",
   "metadata": {},
   "source": [
    "**using whisper model to convert live audio into text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103daaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Infosys_Springboard\\AI_Internship\\venv\\lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "d:\\Infosys_Springboard\\AI_Internship\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from faster_whisper import WhisperModel\n",
    "import time\n",
    "import torch\n",
    "import queue\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = WhisperModel(\"small\", device=device)\n",
    "\n",
    "samplerate = 16000\n",
    "duration = 10\n",
    "q = queue.Queue()\n",
    "\n",
    "def callback(indata, frames, time_info, status):\n",
    "    q.put(indata.copy())\n",
    "\n",
    "audio_buffer = []\n",
    "\n",
    "with sd.InputStream(\n",
    "    samplerate=samplerate,\n",
    "    blocksize=4000,\n",
    "    channels=1,\n",
    "    dtype=\"float32\",\n",
    "    callback=callback\n",
    "):\n",
    "    print(\"Listening...\")\n",
    "    start = time.time()\n",
    "\n",
    "    while time.time() - start < duration:\n",
    "        audio_buffer.append(q.get())\n",
    "\n",
    "print(\"Stopped recording.\")\n",
    "\n",
    "# Combine chunks\n",
    "audio_data = np.concatenate(audio_buffer, axis=0).flatten()\n",
    "\n",
    "# Transcribe whole audio\n",
    "segments, _ = model.transcribe(audio_data)\n",
    "\n",
    "result_text = \" \".join([s.text for s in segments])\n",
    "print(\"Transcription:\\n\", result_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b4bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c4c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fd94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b66bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
